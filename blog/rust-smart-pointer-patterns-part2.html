<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rust's Smart Pointer Patterns — Part 2: The Specialists - Telex</title>
  <meta name="description" content="Cow, OnceCell, OnceLock, LazyLock, Pin, and PhantomData — the specialist wrapper types that solve specific problems the core ownership system doesn't address.">
  <link rel="stylesheet" href="../style.css">
  <link rel="icon" type="image/png" href="../assets/telex-tui.png">
</head>
<body>
  <header>
    <div class="container">
      <a href="/" class="logo-link">
        <img src="../assets/telex-tui.png" alt="Telex logo">
        Telex
      </a>
      <nav>
        <a href="https://telex-tui.github.io/telex-tui/">Book</a>
        <a href="/blog/">Blog</a>
        <a href="https://github.com/telex-tui/telex-tui">GitHub</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <article class="post">
      <h1>Rust's Smart Pointer Patterns — Part 2: The Specialists</h1>
      <div class="post-meta">February 2026</div>

      <p>
        <a href="rust-smart-pointer-patterns-part1.html">Part 1</a> covered the
        core system: <code>Box</code> for heap allocation, <code>Rc</code> and
        <code>Arc</code> for sharing, <code>Cell</code> and <code>RefCell</code>
        for interior mutability, <code>Mutex</code> and <code>RwLock</code> for
        thread-safe mutation, and the combos like <code>Arc&lt;Mutex&lt;T&gt;&gt;</code>
        that wire them together. Those types form a complete ownership toolkit.
        If your problem is "who owns this, who can read it, and who can write
        it," Part 1 has the answer.
      </p>

      <p>
        This post covers the specialists. These are wrapper types that solve
        specific, narrower problems -- deferring allocations, initializing
        values lazily, preventing moves, and marking type-level relationships.
        You don't reach for them every day, but when you need them, nothing
        else will do.
      </p>

      <h2>1. Cow&lt;'a, T&gt; — Clone on Write</h2>

      <p>
        <code>Cow</code> holds either a borrowed reference or an owned value.
        That's it. It's an enum:
      </p>

      <pre><code><span class="kw">enum</span> <span class="ty">Cow</span>&lt;<span class="kw">'a</span>, <span class="ty">B</span>: <span class="ty">ToOwned</span>&gt; {
    <span class="ty">Borrowed</span>(&amp;<span class="kw">'a</span> <span class="ty">B</span>),
    <span class="ty">Owned</span>(&lt;<span class="ty">B</span> <span class="kw">as</span> <span class="ty">ToOwned</span>&gt;::<span class="ty">Owned</span>),
}</code></pre>

      <p>
        The name stands for "clone on write," but the real insight is simpler:
        <code>Cow</code> lets you defer cloning until you actually need to
        mutate. Most of the time, you don't need to mutate. Most of the time,
        the data passes through your function unchanged. <code>Cow</code>
        makes the common case free.
      </p>

      <h3>The problem it solves</h3>

      <p>
        You're writing a function that normalizes user input. Maybe it trims
        whitespace, lowercases certain fields, replaces tabs with spaces. The
        catch: 90% of inputs are already valid. They don't need any
        modification at all.
      </p>

      <p>
        If your function returns <code>String</code>, you're allocating on
        every call -- even when the input passes through unchanged. If it
        returns <code>&amp;str</code>, you can't return a modified string
        because it doesn't live long enough. You're stuck.
      </p>

      <pre><code><span class="kw">use</span> std::borrow::<span class="ty">Cow</span>;

<span class="kw">fn</span> <span class="fn">normalize_username</span>&lt;<span class="kw">'a</span>&gt;(input: &amp;<span class="kw">'a</span> <span class="kw">str</span>) -&gt; <span class="ty">Cow</span>&lt;<span class="kw">'a</span>, <span class="kw">str</span>&gt; {
    <span class="kw">if</span> input.<span class="fn">contains</span>(<span class="str">' '</span>) || input.<span class="fn">chars</span>().<span class="fn">any</span>(|c| c.<span class="fn">is_uppercase</span>()) {
        <span class="cm">// Needs modification — allocate a new String</span>
        <span class="ty">Cow</span>::<span class="ty">Owned</span>(input.<span class="fn">replace</span>(<span class="str">' '</span>, <span class="str">"_"</span>).<span class="fn">to_lowercase</span>())
    } <span class="kw">else</span> {
        <span class="cm">// Already valid — just return the reference, zero allocation</span>
        <span class="ty">Cow</span>::<span class="ty">Borrowed</span>(input)
    }
}</code></pre>

      <p>
        The happy path -- where the username is already clean -- costs nothing.
        No heap allocation, no memcpy, no new <code>String</code>. The caller
        gets back the original <code>&amp;str</code> wrapped in a
        <code>Cow</code>.
      </p>

      <p>
        The unhappy path -- where the username needs work -- allocates a new
        <code>String</code>. But that's fine. You were going to allocate
        anyway if the data needed changing.
      </p>

      <h3>Using the result</h3>

      <p>
        <code>Cow&lt;str&gt;</code> implements <code>Deref&lt;Target = str&gt;</code>,
        so it behaves like a <code>&amp;str</code> in most contexts:
      </p>

      <pre><code><span class="kw">let</span> name = <span class="fn">normalize_username</span>(<span class="str">"alice"</span>);
<span class="fn">println!</span>(<span class="str">"length: {}"</span>, name.<span class="fn">len</span>());       <span class="cm">// works like &amp;str</span>

<span class="cm">// If you need an owned String:</span>
<span class="kw">let</span> owned: <span class="ty">String</span> = name.<span class="fn">into_owned</span>();   <span class="cm">// clones only if Borrowed</span></code></pre>

      <h3>Beyond strings</h3>

      <p>
        <code>Cow</code> works with any type that implements
        <code>ToOwned</code>. The most common pairings:
      </p>

      <ul>
        <li><code>Cow&lt;str&gt;</code> — <code>&amp;str</code> or <code>String</code></li>
        <li><code>Cow&lt;[u8]&gt;</code> — <code>&amp;[u8]</code> or <code>Vec&lt;u8&gt;</code></li>
        <li><code>Cow&lt;Path&gt;</code> — <code>&amp;Path</code> or <code>PathBuf</code></li>
        <li><code>Cow&lt;[T]&gt;</code> — <code>&amp;[T]</code> or <code>Vec&lt;T&gt;</code></li>
      </ul>

      <h3>When you reach for it</h3>

      <p>
        The decision is straightforward. If your function <em>always</em>
        modifies the input, just return <code>String</code>. If it
        <em>never</em> modifies the input, just return <code>&amp;str</code>.
        <code>Cow</code> is for the in-between: functions that <em>usually</em>
        pass data through but <em>sometimes</em> need to modify it. Parsers,
        config processors, validators, normalization layers. If you're
        processing thousands of strings and the majority are already clean,
        <code>Cow</code> saves you thousands of allocations.
      </p>

      <p>
        For C programmers: it's like returning a <code>const char*</code> that
        points to either the original input or a freshly <code>malloc</code>'d
        buffer, except the type system tracks which one it is and handles the
        <code>free</code> for you.
      </p>

      <h2>2. OnceCell&lt;T&gt; and OnceLock&lt;T&gt; — Initialize Exactly Once</h2>

      <p>
        Some values are expensive to create. You don't know at startup whether
        you'll need them. But once you create them, they never change. You want
        lazy initialization with a guarantee: this runs exactly once.
      </p>

      <h3>The problem without them</h3>

      <p>
        Without <code>OnceCell</code> or <code>OnceLock</code>, you end up
        writing the manual version:
      </p>

      <pre><code><span class="kw">use</span> std::sync::<span class="ty">Mutex</span>;

<span class="kw">static</span> <span class="ty">CONFIG</span>: <span class="ty">Mutex</span>&lt;<span class="ty">Option</span>&lt;<span class="ty">AppConfig</span>&gt;&gt; = <span class="ty">Mutex</span>::<span class="fn">new</span>(<span class="ty">None</span>);

<span class="kw">fn</span> <span class="fn">get_config</span>() -&gt; <span class="ty">AppConfig</span> {
    <span class="kw">let</span> <span class="kw">mut</span> guard = <span class="ty">CONFIG</span>.<span class="fn">lock</span>().<span class="fn">unwrap</span>();
    <span class="kw">if</span> guard.<span class="fn">is_none</span>() {
        *guard = <span class="ty">Some</span>(<span class="fn">load_config_from_disk</span>());
    }
    guard.<span class="fn">clone</span>().<span class="fn">unwrap</span>()
}</code></pre>

      <p>
        This works, but it's noisy. You're managing a <code>Mutex</code>
        around an <code>Option</code>, manually checking whether the value
        exists, and cloning on every access because you can't hold the lock
        guard forever. And every subsequent caller still pays for the lock,
        even though the value was set on the first call and never changes.
      </p>

      <h3>OnceLock: the thread-safe one</h3>

      <p>
        <code>OnceLock</code> is the one you'll use most. It's safe to share
        across threads and its initialization is guaranteed to run exactly once,
        even if multiple threads race to initialize it.
      </p>

      <pre><code><span class="kw">use</span> std::sync::<span class="ty">OnceLock</span>;

<span class="kw">static</span> <span class="ty">CONFIG</span>: <span class="ty">OnceLock</span>&lt;<span class="ty">AppConfig</span>&gt; = <span class="ty">OnceLock</span>::<span class="fn">new</span>();

<span class="kw">fn</span> <span class="fn">get_config</span>() -&gt; &amp;<span class="kw">'static</span> <span class="ty">AppConfig</span> {
    <span class="ty">CONFIG</span>.<span class="fn">get_or_init</span>(|| <span class="fn">load_config_from_disk</span>())
}</code></pre>

      <p>
        That's it. The first call runs the closure, stores the result, and
        returns a reference to it. Every subsequent call returns the same
        reference immediately -- no lock contention, no cloning, no
        <code>Option</code> unwrapping.
      </p>

      <p>
        <code>get_or_init</code> is the key method. It takes a closure that
        produces the value. If the cell is empty, it runs the closure and
        stores the result. If the cell is already full, it ignores the closure
        entirely and returns what's there.
      </p>

      <h3>OnceCell: the single-threaded one</h3>

      <p>
        <code>OnceCell</code> is the same concept but without the
        thread-safety machinery. It lives in <code>std::cell</code> instead
        of <code>std::sync</code>:
      </p>

      <pre><code><span class="kw">use</span> std::cell::<span class="ty">OnceCell</span>;

<span class="kw">struct</span> <span class="ty">Parser</span> {
    regex_cache: <span class="ty">OnceCell</span>&lt;<span class="ty">Regex</span>&gt;,
}

<span class="kw">impl</span> <span class="ty">Parser</span> {
    <span class="kw">fn</span> <span class="fn">new</span>() -&gt; <span class="kw">Self</span> {
        <span class="ty">Parser</span> { regex_cache: <span class="ty">OnceCell</span>::<span class="fn">new</span>() }
    }

    <span class="kw">fn</span> <span class="fn">regex</span>(&amp;<span class="kw">self</span>) -&gt; &amp;<span class="ty">Regex</span> {
        <span class="kw">self</span>.regex_cache.<span class="fn">get_or_init</span>(|| {
            <span class="ty">Regex</span>::<span class="fn">new</span>(<span class="str">r"\d{4}-\d{2}-\d{2}"</span>).<span class="fn">unwrap</span>()
        })
    }
}</code></pre>

      <p>
        Use <code>OnceCell</code> when the value lives inside a struct that
        isn't shared across threads. Use <code>OnceLock</code> when you need
        <code>static</code> globals or cross-thread sharing.
      </p>

      <h3>What they replaced</h3>

      <p>
        Before these types were in the standard library, the
        <code>lazy_static</code> crate was the go-to. If you see
        <code>lazy_static!</code> in older codebases, this is what it was
        doing. <code>OnceLock</code> and <code>OnceCell</code> (stabilized in
        Rust 1.70) replaced <code>lazy_static</code> for most uses, with the
        advantage of being in <code>std</code>, requiring no macros, and giving
        you explicit control over when initialization happens.
      </p>

      <h3>When you reach for them</h3>

      <p>
        Compiled regexes. Database connection pools. Lookup tables parsed from
        files. Configuration loaded from environment variables. Any value
        that's expensive to create, needed zero or one time, and immutable once
        created. The pattern is always the same: declare the cell, call
        <code>get_or_init</code> at the point of first use.
      </p>

      <h2>3. LazyLock&lt;T&gt; — OnceLock with a Built-in Initializer</h2>

      <p>
        <code>OnceLock</code> separates declaration from initialization. You
        declare the cell in one place and provide the initializer at the point
        of first use. <code>LazyLock</code> bundles them together: you provide
        the initialization closure at declaration time.
      </p>

      <pre><code><span class="kw">use</span> std::sync::<span class="ty">LazyLock</span>;
<span class="kw">use</span> regex::<span class="ty">Regex</span>;

<span class="kw">static</span> <span class="ty">DATE_REGEX</span>: <span class="ty">LazyLock</span>&lt;<span class="ty">Regex</span>&gt; = <span class="ty">LazyLock</span>::<span class="fn">new</span>(|| {
    <span class="ty">Regex</span>::<span class="fn">new</span>(<span class="str">r"^\d{4}-\d{2}-\d{2}$"</span>).<span class="fn">unwrap</span>()
});

<span class="kw">static</span> <span class="ty">LOOKUP_TABLE</span>: <span class="ty">LazyLock</span>&lt;<span class="ty">HashMap</span>&lt;<span class="ty">String</span>, <span class="ty">i32</span>&gt;&gt; = <span class="ty">LazyLock</span>::<span class="fn">new</span>(|| {
    <span class="kw">let</span> <span class="kw">mut</span> m = <span class="ty">HashMap</span>::<span class="fn">new</span>();
    m.<span class="fn">insert</span>(<span class="str">"critical"</span>.<span class="fn">into</span>(), <span class="num">1</span>);
    m.<span class="fn">insert</span>(<span class="str">"warning"</span>.<span class="fn">into</span>(), <span class="num">2</span>);
    m.<span class="fn">insert</span>(<span class="str">"info"</span>.<span class="fn">into</span>(), <span class="num">3</span>);
    m
});

<span class="kw">fn</span> <span class="fn">is_valid_date</span>(s: &amp;<span class="kw">str</span>) -&gt; <span class="ty">bool</span> {
    <span class="ty">DATE_REGEX</span>.<span class="fn">is_match</span>(s)  <span class="cm">// initialized on first call</span>
}</code></pre>

      <p>
        That <code>LazyLock::new(|| ...)</code> is essentially what the
        <code>lazy_static!</code> macro used to generate. The closure runs on
        first access, the result is stored, and subsequent accesses return the
        stored value. No lock contention after initialization.
      </p>

      <h3>LazyLock vs OnceLock</h3>

      <p>
        The difference is about where the initializer lives:
      </p>

      <ul>
        <li><strong>OnceLock:</strong> You provide the initialization closure at
          the call site. The cell can be initialized differently depending on
          who calls <code>get_or_init</code> first (though in practice you'd
          always pass the same closure).</li>
        <li><strong>LazyLock:</strong> The initialization closure is baked in at
          declaration time. Every access gets the same initialization logic.
          You can't change your mind later.</li>
      </ul>

      <p>
        For <code>static</code> globals with fixed initialization -- which is
        the most common case -- <code>LazyLock</code> is the cleaner choice.
        The initialization is right there with the declaration, and you don't
        have to worry about passing the right closure everywhere. For struct
        fields or situations where the initialization depends on runtime data,
        <code>OnceLock</code> gives you more flexibility.
      </p>

      <h3>When you reach for it</h3>

      <p>
        <code>LazyLock</code> is for global/static values where you know the
        initialization logic upfront. Compiled regexes, pre-built lookup
        tables, parsed configuration, constant data loaded from embedded
        files. If you're typing <code>static FOO: ... = ...</code> and the
        right-hand side can't be a <code>const</code>, <code>LazyLock</code>
        is probably what you want.
      </p>

      <h2>4. Pin&lt;T&gt; — Promise This Won't Move</h2>

      <p>
        This is the hardest type in the entire smart pointer toolkit. That's
        not an apology -- it's a warning. <code>Pin</code> exists to solve a
        problem that most languages pretend doesn't exist, and it earns its
        complexity honestly. Let's take it step by step.
      </p>

      <h3>The problem: self-referential structs</h3>

      <p>
        Most values in Rust can move freely in memory. When you push a value
        into a <code>Vec</code> or return it from a function, the bytes get
        copied to a new location. This is fine for most types -- an
        <code>i32</code> is an <code>i32</code> no matter where it lives, and
        a <code>String</code> is a pointer to the heap plus a length, so
        moving the <code>String</code> struct doesn't affect the heap data it
        points to.
      </p>

      <p>
        But what if a struct contains a pointer to <em>itself</em>? If the
        struct moves, that pointer now points to where the struct <em>used
        to be</em>, not where it is now. The pointer dangles.
      </p>

      <pre><code><span class="cm">// Conceptual illustration — you can't actually write this in safe Rust</span>
<span class="kw">struct</span> <span class="ty">SelfRef</span> {
    data: <span class="ty">String</span>,
    ptr_to_data: *<span class="kw">const</span> <span class="ty">String</span>,  <span class="cm">// points to self.data</span>
}
<span class="cm">// If SelfRef moves, ptr_to_data still points to the old location.</span>
<span class="cm">// Use-after-move. Bad.</span></code></pre>

      <p>
        In C terms: you have a struct that stores a pointer to one of its own
        fields. If you <code>memcpy</code> the struct to a new address, that
        pointer is now stale. Rust's <code>Pin</code> is like telling the
        compiler "this value has the same address for its entire lifetime --
        don't move it."
      </p>

      <h3>Why async makes this real</h3>

      <p>
        You might think self-referential structs are exotic. They're not.
        Every <code>async fn</code> generates one. When the compiler
        transforms an <code>async fn</code> into a state machine, the
        resulting struct holds local variables across <code>.await</code>
        points. If one of those locals is a reference to another local,
        you've got a self-referential struct:
      </p>

      <pre><code><span class="kw">async fn</span> <span class="fn">example</span>() {
    <span class="kw">let</span> data = <span class="fn">vec!</span>[<span class="num">1</span>, <span class="num">2</span>, <span class="num">3</span>];
    <span class="kw">let</span> slice = &amp;data[..];       <span class="cm">// borrows data</span>
    <span class="fn">some_async_op</span>().<span class="kw">await</span>;       <span class="cm">// state machine suspends here</span>
    <span class="fn">println!</span>(<span class="str">"{:?}"</span>, slice);     <span class="cm">// uses slice after resuming</span>
}</code></pre>

      <p>
        The compiler-generated state machine struct holds both <code>data</code>
        and <code>slice</code>. <code>slice</code> points into
        <code>data</code>'s memory. If this struct moved, <code>slice</code>
        would dangle. <code>Pin</code> prevents the move.
      </p>

      <h3>What Pin actually is</h3>

      <p>
        <code>Pin&lt;P&gt;</code> wraps a pointer type <code>P</code> (like
        <code>&amp;mut T</code> or <code>Box&lt;T&gt;</code>) and restricts
        what you can do with it. Specifically, you can't get a
        <code>&amp;mut T</code> from a <code>Pin&lt;&amp;mut T&gt;</code>
        unless <code>T</code> implements <code>Unpin</code>. Without
        <code>&amp;mut T</code>, you can't use <code>mem::swap</code> or
        <code>mem::replace</code> to move the value out.
      </p>

      <p>
        Most types implement <code>Unpin</code> automatically. An
        <code>i32</code>, a <code>String</code>, a <code>Vec&lt;T&gt;</code>
        -- they don't contain self-references, so moving them is harmless.
        For these types, <code>Pin</code> imposes no restriction at all. It
        only matters for <code>!Unpin</code> types -- and the main
        <code>!Unpin</code> types you'll encounter are futures generated by
        <code>async</code> blocks.
      </p>

      <h3>The practical surface</h3>

      <p>
        Most Rust programmers encounter <code>Pin</code> through async and
        don't need to deeply understand the internals to use it. Here's
        what you'll actually type:
      </p>

      <p>
        <strong>Pin&lt;Box&lt;T&gt;&gt;</strong> — Heap-allocate the value
        and pin it there. The <code>Box</code> pointer may move, but the data
        on the heap stays put. This is the most common pinning strategy:
      </p>

      <pre><code><span class="kw">use</span> std::pin::<span class="ty">Pin</span>;
<span class="kw">use</span> std::future::<span class="ty">Future</span>;

<span class="cm">// Returning a future from a trait method using dynamic dispatch</span>
<span class="kw">fn</span> <span class="fn">fetch</span>(&amp;<span class="kw">self</span>) -&gt; <span class="ty">Pin</span>&lt;<span class="ty">Box</span>&lt;<span class="kw">dyn</span> <span class="ty">Future</span>&lt;<span class="ty">Output</span> = <span class="ty">Vec</span>&lt;<span class="ty">u8</span>&gt;&gt; + <span class="ty">Send</span> + <span class="kw">'_</span>&gt;&gt; {
    <span class="ty">Box</span>::<span class="fn">pin</span>(<span class="kw">async move</span> {
        <span class="cm">// your async implementation</span>
        <span class="fn">vec!</span>[]
    })
}</code></pre>

      <p>
        <strong>pin!()</strong> — Pin a value to the stack. Available as
        <code>std::pin::pin!</code> since Rust 1.68:
      </p>

      <pre><code><span class="kw">use</span> std::pin::<span class="fn">pin</span>;

<span class="kw">let</span> fut = <span class="fn">pin!</span>(<span class="fn">some_async_operation</span>());
<span class="cm">// fut is Pin&lt;&amp;mut impl Future&gt; — pinned to the stack</span></code></pre>

      <p>
        <strong>The Future::poll signature:</strong> If you ever implement
        <code>Future</code> manually, the <code>poll</code> method takes
        <code>self: Pin&lt;&amp;mut Self&gt;</code>. This is the guarantee
        the runtime relies on: by the time <code>poll</code> is called, the
        future won't move.
      </p>

      <h3>The honest assessment</h3>

      <p>
        <code>Pin</code> is genuinely complex. The interaction between
        <code>Pin</code>, <code>Unpin</code>, and structural pinning is one
        of the most subtle corners of the language. But here's the good news:
        for application code, you almost never need to think about it beyond
        "<code>Box::pin(async move { ... })</code> when the compiler asks for
        it." Library authors who implement custom futures or self-referential
        data structures need the deeper understanding. Application authors
        mostly need to know it exists and reach for <code>Box::pin</code>.
      </p>

      <h3>When you reach for it</h3>

      <p>
        You don't "reach for" <code>Pin</code> the way you reach for
        <code>Cow</code> or <code>OnceLock</code>. The compiler tells you
        when you need it. That happens in three situations: returning futures
        as trait objects, storing futures in struct fields, and implementing
        the <code>Future</code> trait by hand. In all three cases,
        <code>Box::pin()</code> is the answer that gets you moving.
      </p>

      <h2>5. PhantomData&lt;T&gt; — Zero-Size Type-Level Marker</h2>

      <p>
        <code>PhantomData</code> doesn't hold any data. It has zero size and
        compiles to nothing. Its entire purpose is telling the compiler about
        a type relationship that the struct's fields don't express on their
        own.
      </p>

      <h3>The problem it solves</h3>

      <p>
        You're writing a generic struct that has a type parameter
        <code>T</code>, but none of the struct's fields actually contain a
        <code>T</code>. The compiler complains: "parameter <code>T</code> is
        never used."
      </p>

      <pre><code><span class="cm">// This doesn't compile: T is unused</span>
<span class="kw">struct</span> <span class="ty">Slice</span>&lt;<span class="kw">'a</span>, <span class="ty">T</span>&gt; {
    start: *<span class="kw">const</span> <span class="ty">T</span>,
    end: *<span class="kw">const</span> <span class="ty">T</span>,
    <span class="cm">// The compiler doesn't know this struct "owns" or "borrows" T</span>
    <span class="cm">// through these raw pointers.</span>
}</code></pre>

      <p>
        Raw pointers don't carry ownership or lifetime information. The
        compiler doesn't know whether this struct logically owns the
        <code>T</code> values or just points to them. This matters for
        drop checking, variance (whether <code>Slice&lt;&amp;'long T&gt;</code>
        can be used where <code>Slice&lt;&amp;'short T&gt;</code> is
        expected), and auto-trait inference.
      </p>

      <p>
        <code>PhantomData</code> fills the gap:
      </p>

      <pre><code><span class="kw">use</span> std::marker::<span class="ty">PhantomData</span>;

<span class="kw">struct</span> <span class="ty">Slice</span>&lt;<span class="kw">'a</span>, <span class="ty">T</span>&gt; {
    start: *<span class="kw">const</span> <span class="ty">T</span>,
    end: *<span class="kw">const</span> <span class="ty">T</span>,
    _marker: <span class="ty">PhantomData</span>&lt;&amp;<span class="kw">'a</span> <span class="ty">T</span>&gt;,  <span class="cm">// "pretend" we borrow a T with lifetime 'a</span>
}</code></pre>

      <p>
        The <code>PhantomData&lt;&amp;'a T&gt;</code> tells the compiler: "treat
        this struct as if it borrows a <code>&amp;'a T</code>." The compiler
        can now correctly reason about lifetimes and variance. At runtime, the
        field takes zero bytes.
      </p>

      <h3>Common uses</h3>

      <p>
        <strong>Associating a lifetime with a raw pointer:</strong>
      </p>

      <pre><code><span class="kw">struct</span> <span class="ty">RawIter</span>&lt;<span class="kw">'a</span>, <span class="ty">T</span>&gt; {
    ptr: *<span class="kw">const</span> <span class="ty">T</span>,
    end: *<span class="kw">const</span> <span class="ty">T</span>,
    _marker: <span class="ty">PhantomData</span>&lt;&amp;<span class="kw">'a</span> <span class="ty">T</span>&gt;,
}</code></pre>

      <p>
        <strong>Marking a type parameter as "used" for type-level
        logic:</strong>
      </p>

      <pre><code><span class="cm">// A typed ID that prevents mixing user IDs with order IDs</span>
<span class="kw">struct</span> <span class="ty">Id</span>&lt;<span class="ty">T</span>&gt; {
    value: <span class="ty">u64</span>,
    _marker: <span class="ty">PhantomData</span>&lt;<span class="ty">T</span>&gt;,
}

<span class="kw">struct</span> <span class="ty">User</span>;
<span class="kw">struct</span> <span class="ty">Order</span>;

<span class="kw">let</span> user_id: <span class="ty">Id</span>&lt;<span class="ty">User</span>&gt; = <span class="ty">Id</span> { value: <span class="num">42</span>, _marker: <span class="ty">PhantomData</span> };
<span class="kw">let</span> order_id: <span class="ty">Id</span>&lt;<span class="ty">Order</span>&gt; = <span class="ty">Id</span> { value: <span class="num">42</span>, _marker: <span class="ty">PhantomData</span> };
<span class="cm">// user_id and order_id are different types despite both holding u64</span></code></pre>

      <p>
        That last example is really a newtype pattern with a generic twist.
        The <code>PhantomData</code> makes the type parameter <code>T</code>
        "used" so the compiler accepts it, even though no actual
        <code>T</code> value is stored. The result: <code>Id&lt;User&gt;</code>
        and <code>Id&lt;Order&gt;</code> are distinct types with zero runtime
        overhead.
      </p>

      <h3>When you reach for it</h3>

      <p>
        <code>PhantomData</code> is more advanced than the other types in this
        post. You'll encounter it when writing unsafe abstractions over raw
        pointers, implementing custom iterators over borrowed data, or building
        type-level state machines where a type parameter carries meaning but no
        data. If the compiler says "unused type parameter," and you know the
        parameter is conceptually part of the type, <code>PhantomData</code>
        is the answer.
      </p>

      <h2>When to Reach for What: The Full Decision Tree</h2>

      <p>
        Here's the combined map across both parts. Start with what you need,
        and follow the path.
      </p>

      <p>
        <strong>I need to put data on the heap.</strong> Use
        <code>Box&lt;T&gt;</code>. Single owner, fixed size on the stack,
        data on the heap. This is your <code>malloc</code>.
      </p>

      <p>
        <strong>I need multiple owners (single-threaded).</strong> Use
        <code>Rc&lt;T&gt;</code>. Reference-counted, clones bump the count,
        drops decrement it, last drop frees the data.
      </p>

      <p>
        <strong>I need multiple owners (multi-threaded).</strong> Use
        <code>Arc&lt;T&gt;</code>. Same as <code>Rc</code> but with atomic
        reference counting, safe to send across threads.
      </p>

      <p>
        <strong>I need to mutate through a shared reference
        (single-threaded).</strong> Use <code>RefCell&lt;T&gt;</code> for
        full borrow checking at runtime, or <code>Cell&lt;T&gt;</code> for
        small <code>Copy</code> types where you just need get/set.
      </p>

      <p>
        <strong>I need to mutate through a shared reference
        (multi-threaded).</strong> Use <code>Mutex&lt;T&gt;</code>. Or
        <code>RwLock&lt;T&gt;</code> if reads heavily outnumber writes.
      </p>

      <p>
        <strong>I need shared + mutable (single-threaded).</strong> Combine:
        <code>Rc&lt;RefCell&lt;T&gt;&gt;</code>.
      </p>

      <p>
        <strong>I need shared + mutable (multi-threaded).</strong> Combine:
        <code>Arc&lt;Mutex&lt;T&gt;&gt;</code> or
        <code>Arc&lt;RwLock&lt;T&gt;&gt;</code>.
      </p>

      <p>
        <strong>I have a function that usually passes data through but
        sometimes modifies it.</strong> Use <code>Cow&lt;'a, T&gt;</code>.
        Borrow on the happy path, allocate only when you must.
      </p>

      <p>
        <strong>I have an expensive value that needs lazy, one-time
        initialization.</strong> Use <code>OnceLock&lt;T&gt;</code> for
        thread-safe or <code>OnceCell&lt;T&gt;</code> for single-threaded.
      </p>

      <p>
        <strong>I have a static value with a known initializer.</strong> Use
        <code>LazyLock&lt;T&gt;</code>. It's <code>OnceLock</code> with the
        initialization baked in.
      </p>

      <p>
        <strong>The compiler says my future needs to be pinned.</strong> Use
        <code>Box::pin(async move { ... })</code> or the <code>pin!()</code>
        macro. This comes up with async trait objects and stored futures.
      </p>

      <p>
        <strong>I have a generic struct with an unused type parameter.</strong>
        Add a <code>PhantomData&lt;T&gt;</code> field to tell the compiler
        how the parameter relates to the struct.
      </p>

      <h2>Putting It All Together</h2>

      <p>
        Between <a href="rust-smart-pointer-patterns-part1.html">Part 1</a>
        and this post, you've seen the full set of wrapper types that Rust
        provides for managing ownership, sharing, mutation, lazy initialization,
        conditional allocation, and memory pinning. That's a lot of types.
        But the decision tree above should make it manageable -- you're never
        choosing from all of them at once. You're answering a specific
        question about your code, and the answer narrows to one or two types.
      </p>

      <p>
        The core system from Part 1 handles the structural question: who owns
        this, who can see it, and who can change it. The specialists from this
        post handle the tactical questions: can I avoid allocating, can I
        defer work, can I promise something about memory layout.
      </p>

      <p>
        If you've also read
        <a href="40-rust-patterns-that-matter.html">40 Rust Patterns That
        Matter</a>, you now have a solid intermediate toolkit: the patterns
        for working with <code>Option</code>, <code>Result</code>, iterators,
        and collections, plus the wrapper types for managing ownership and
        memory at every scale. The three posts complement each other -- the
        40 patterns tell you <em>what to do</em> with values, and the smart
        pointer series tells you <em>how to hold</em> them.
      </p>

    </article>
  </main>

  <footer>
    <div class="container">
      MIT - Copyright &copy; 2025 Mark Branion
    </div>
  </footer>
</body>
</html>
