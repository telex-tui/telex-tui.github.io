<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Designing a TUI Framework in Rust - Part 2 - Telex</title>
  <meta name="description" content="How Telex evolved: channels for external events, effects, error boundaries, custom widgets, and dirty render skipping.">
  <link rel="stylesheet" href="../style.css">
  <link rel="icon" type="image/png" href="../assets/telex-tui.png">
</head>
<body>
  <header>
    <div class="container">
      <a href="/" class="logo-link">
        <img src="../assets/telex-tui.png" alt="Telex logo">
        Telex
      </a>
      <nav>
        <a href="https://telex-tui.github.io/telex-tui/">Book</a>
        <a href="/blog/">Blog</a>
        <a href="https://github.com/telex-tui/telex-tui">GitHub</a>
      </nav>
    </div>
  </header>

  <main class="container">
    <article class="post">
      <h1>Designing a TUI Framework in Rust - Part 2</h1>
      <div class="post-meta">February 2026</div>
      <p class="series-nav">Part 2 of 2 in <a href="#series-index">Designing a TUI Framework in Rust</a>.</p>
      <p class="series-nav">Previous: <a href="designing-a-tui-framework-in-rust.html">Part 1: The Foundational Design Decisions</a></p>

      <p>
        The <a href="designing-a-tui-framework-in-rust.html">first version</a> of Telex worked well
        for self-contained applications - counters, forms, lists. But real applications need
        to talk to the outside world, recover from errors, and run side effects. Here's what changed
        and why.
      </p>

      <h2>Killing hook order dependency</h2>

      <p>
        The original Telex had two hook APIs. The first was index-based, following React's model:
        hooks were stored in a <code>Vec</code>, and each call to <code>use_state</code> returned
        the next item by incrementing a counter. This worked, but it came with React's rules -
        no hooks in conditionals, no hooks in loops, always call them in the same order, or the
        indices desynchronize and the wrong state comes back.
      </p>
      <p>
        The keyed API already existed alongside it, using <code>TypeId</code> keys generated by
        the <code>state!</code> macro. It had none of these problems. So the index-based API was
        removed entirely before anyone depended on it.
      </p>
      <pre><code><span class="cm">// Before: index-based (removed)</span>
<span class="kw">let</span> count = cx.<span class="fn">use_state</span>(|| <span class="num">0</span>);  <span class="cm">// hook 0</span>
<span class="kw">let</span> name = cx.<span class="fn">use_state</span>(|| <span class="str">""</span>);   <span class="cm">// hook 1</span>
<span class="cm">// swap these two lines and everything breaks</span>

<span class="cm">// After: keyed (current)</span>
<span class="kw">let</span> count = <span class="mac">state!</span>(cx, || <span class="num">0</span>);     <span class="cm">// key = TypeId of anonymous struct at this call site</span>
<span class="kw">let</span> name = <span class="mac">state!</span>(cx, || <span class="str">""</span>);      <span class="cm">// different call site = different key</span>
<span class="cm">// order doesn't matter, conditionals are fine</span></code></pre>
      <p>
        The cost is a <code>HashMap</code> lookup instead of a <code>Vec</code> index. In practice,
        components have a handful of hooks and the lookup is noise compared to the terminal I/O
        that follows. The benefit is that an entire class of runtime panics disappears.
      </p>

      <h2>Talking to the outside world</h2>

      <p>
        The first version of Telex had no story for external events. If you wanted to read from a
        WebSocket or a MIDI device, you were on your own - spawn a thread, put data somewhere,
        hope the render loop notices. There was no mechanism for a background thread to wake the
        event loop, so data sat in a buffer until the next keypress triggered a re-render.
      </p>
      <p>
        Channels and ports solve this. A channel is a typed, inbound message queue. A port adds
        an outbound direction. The key insight is where the thread boundary falls:
      </p>
      <pre><code><span class="kw">let</span> ch = <span class="mac">channel!</span>(cx, <span class="ty">SensorReading</span>);

<span class="cm">// ch.tx() returns a WakingSender â€” Send + Clone</span>
<span class="cm">// Hand it to any thread</span>
<span class="kw">let</span> tx = ch.<span class="fn">tx</span>();
std::thread::<span class="fn">spawn</span>(<span class="kw">move</span> || {
    <span class="kw">loop</span> {
        <span class="kw">let</span> reading = sensor.<span class="fn">read</span>();
        tx.<span class="fn">send</span>(reading).<span class="fn">ok</span>();
    }
});

<span class="cm">// In the component: messages that arrived since last frame</span>
<span class="kw">for</span> msg <span class="kw">in</span> ch.<span class="fn">get</span>() {
    <span class="cm">// process this frame's messages</span>
}</code></pre>
      <p>
        The <code>Sender</code> is <code>Send</code> - it crosses the thread boundary.
        Everything else (<code>State</code>, <code>View</code>, <code>Scope</code>) stays on the
        main thread. No <code>Arc</code>, no <code>Send</code> bounds on components, no mutex
        contention on state.
      </p>
      <p>
        At the top of each frame, the run loop drains all registered channels. Components see only
        messages that arrived since the last render. This is frame-buffered delivery - messages
        are batched per frame rather than processed one at a time.
      </p>

      <h3>WakingSender</h3>
      <p>
        A plain <code>mpsc::Sender</code> drops messages into a queue, but nothing tells the event
        loop to wake up. Without a wake mechanism, the loop polls on a 16ms timeout, meaning
        external data has up to 16ms of latency before it appears on screen.
        <code>WakingSender</code> solves this by signaling the event loop on every send, so the
        render happens immediately. Near-zero latency, no polling overhead when idle.
      </p>

      <h2>Effects</h2>

      <p>
        Side effects - logging, starting a timer, opening a file - can't happen during
        tree construction. The component function builds a description of the UI; it shouldn't
        mutate the world while doing so. Effects run after render, when the view tree is complete
        and the buffer has been flushed:
      </p>
      <pre><code><span class="kw">let</span> count = <span class="mac">state!</span>(cx, || <span class="num">0</span>);

<span class="cm">// Runs after render, only when count changes</span>
<span class="mac">effect!</span>(cx, count.<span class="fn">get</span>(), |&amp;c| {
    <span class="fn">println!</span>(<span class="str">"Count is now {}"</span>, c);
    || {} <span class="cm">// cleanup (runs before next effect, or on teardown)</span>
});

<span class="cm">// Runs once, on first render only</span>
<span class="mac">effect_once!</span>(cx, || {
    <span class="fn">println!</span>(<span class="str">"Component mounted"</span>);
    || <span class="fn">println!</span>(<span class="str">"Cleanup on exit"</span>)
});</code></pre>
      <p>
        Effects use the same <code>TypeId</code> keying as state - order-independent, safe in
        conditionals. The run loop renders, flushes effects, and if any effect modified state,
        re-renders once more. A cycle detector panics if effects fire more than 100 times in 10
        frames, catching infinite loops early rather than hanging the terminal.
      </p>
      <p>
        Each effect returns a cleanup function. Cleanups run before the next invocation of the same
        effect and on application exit. This is essential for timers, file handles, and anything
        else that needs deterministic teardown.
      </p>

      <h2>Error boundaries</h2>

      <p>
        When your data comes from external sources, it crashes. A device gets unplugged, a server
        returns malformed JSON, a codec panics on unexpected input. In the first version, a panic
        in any callback or rendering function killed the entire application.
      </p>
      <p>
        Error boundaries make failure containable:
      </p>
      <pre><code><span class="ty">View</span>::<span class="fn">error_boundary</span>()
    .<span class="fn">child</span>(risky_widget)
    .<span class="fn">fallback</span>(|err| <span class="ty">View</span>::<span class="fn">text</span>(<span class="mac">format!</span>(<span class="str">"Error: {}"</span>, err)))
    .<span class="fn">build</span>()</code></pre>
      <p>
        When a panic occurs inside the boundary, <code>catch_unwind</code> catches it, the subtree
        is replaced with the fallback view, effect cleanups for the failed subtree run, and the rest
        of the application continues. Without an error boundary wrapping it, a panic propagates to
        the run loop and terminates the app - same as before. Safety is opt-in, not forced
        overhead.
      </p>

      <h2>The escape hatch: custom widgets</h2>

      <p>
        The <code>View</code> enum is closed by design. You can compose existing widgets to build
        new ones - a settings panel is a <code>VStack</code> of <code>TextInput</code> and
        <code>Checkbox</code> widgets. But some things can't be composed. A piano roll, a
        spectrogram, a hex editor - these need direct control over character cells.
      </p>
      <p>
        <code>View::Custom</code> is the escape hatch. It accepts anything implementing the
        <code>Widget</code> trait:
      </p>
      <pre><code><span class="kw">trait</span> <span class="ty">Widget</span> {
    <span class="kw">fn</span> <span class="fn">render</span>(&amp;<span class="kw">self</span>, area: <span class="ty">Rect</span>, buf: &amp;<span class="kw">mut</span> <span class="ty">Buffer</span>);
    <span class="kw">fn</span> <span class="fn">focusable</span>(&amp;<span class="kw">self</span>) -&gt; <span class="kw">bool</span> { <span class="kw">false</span> }
    <span class="kw">fn</span> <span class="fn">handle_key</span>(&amp;<span class="kw">mut self</span>, key: <span class="ty">KeyEvent</span>) -&gt; <span class="kw">bool</span> { <span class="kw">false</span> }
}</code></pre>
      <p>
        A custom widget participates fully in layout, focus navigation, and the render pipeline. It
        gets a rectangular area and a mutable reference to the cell buffer. The framework doesn't
        know or care what it draws - it just reserves the space and hands over control.
      </p>
      <p>
        This is the trade-off acknowledged in the first post made explicit: the enum is closed for
        built-in widgets (fast, exhaustive, debuggable), but open for user-defined rendering when
        composition isn't enough.
      </p>

      <h2>Dirty render skipping</h2>

      <p>
        The first version re-rendered every frame unconditionally. For a TUI app that's mostly idle
        - waiting for the user to press a key - this wastes CPU rebuilding the same
        view tree and diffing the same buffer, finding nothing changed.
      </p>
      <p>
        The wake mechanism fixes this. Three things can make a frame "dirty":
      </p>
      <ul>
        <li>A <code>State</code> mutation sets its <code>dirty</code> flag</li>
        <li>Terminal input arrives (keypress, mouse, resize)</li>
        <li>A channel receives data (via <code>WakingSender</code>'s wake flag)</li>
      </ul>
      <p>
        If none of these are true, the event loop skips the entire render pass and goes back to
        sleep. Idle CPU drops from 5-10% to near zero.
      </p>
      <p>
        This sounds straightforward, but getting it right means every path that produces new data
        must set the appropriate flag. A recent bug illustrated this precisely: the
        <code>stream!</code>, <code>text_stream!</code>, and <code>text_stream_with_restart!</code>
        macros used plain <code>mpsc::Sender</code> with no wake mechanism. Tokens arrived from
        background threads, but the event loop never noticed - no dirty flag, no re-render.
        Data sat invisible until the user happened to press a key. The fix was to add a wake flag
        to stream handles, set by the background thread on each token, checked by the event loop
        alongside the other dirty sources.
      </p>
      <p>
        Every new data path into the render loop is a potential wake bug. The pattern is always the
        same: data arrives, flag is set, loop wakes, frame renders. Miss the flag and you get
        stale screens. It's the kind of invariant that's easy to state and easy to violate.
      </p>

      <h2>What's next</h2>

      <p>
        The architecture is stable, but there's room to grow. Component-level memoization would let
        subtrees skip re-evaluation when their inputs haven't changed - not needed yet at TUI
        scale, but the component identity mechanism is already in place to support it. Layout caching
        would avoid recalculating constraints that haven't changed. And there's a model layer question:
        ports and reducers hint at state that doesn't belong to any one component - a database
        handle, a network connection, a shared resource. <code>use_context</code> partially addresses
        this, but a standalone store that lives outside the component tree may eventually be needed.
      </p>
      <p>
        The lesson from the past year is that each of these changes was motivated by a concrete
        failure, not a theoretical concern. Index-based hooks were removed because they caused
        panics. Channels were added because applications needed external data. Effects were added
        because side effects during render caused bugs. Error boundaries were added because external
        sources crash. The architecture evolves by hitting walls and finding doors.
      </p>
    </article>
  </main>

  <footer>
    <div class="container">
      MIT - Copyright &copy; 2025 Mark Branion
    </div>
  </footer>
</body>
</html>
